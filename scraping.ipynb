{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "#### What is scraping?\n",
    "\n",
    "Scraping is just a fancy word that stands for a **data collection** activity. To be more specific, scraping is a (not so new, did you ever heard about *screen reading*?) way to perform data collection from webpages."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "#### Why scraping?\n",
    "\n",
    "\"*Data is the new oil*\" \n",
    "To verify our hypthesis, get insights and to understand the world quantitatively, we just need data!\n",
    "\n",
    "Web is full of datas, but in a **unstructured** format, so scraping is **searching + structuring information** in a useful way for needs."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "#### When we should scrape the web?\n",
    "\n",
    "When an official API is not available. APIs are \"services\", websites offer to give access to their data in a programmatic way. \n",
    "\n",
    "A website's API is implicitely telling which data and how this data should be accessed.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "Example with a [free access API](https://datausa.io/about/api/):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mRunning cells with 'Python 3.10.8 64-bit' requires ipykernel package.\n",
      "\u001b[1;31mRun the following command to install 'ipykernel' into the Python environment. \n",
      "\u001b[1;31mCommand: '/usr/local/bin/python3 -m pip install ipykernel -U --user --force-reinstall'"
     ]
    }
   ],
   "source": [
    "# make a request to datausa.io API\n",
    "\n",
    "import requests\n",
    "\n",
    "url=\"https://datausa.io/api/data\"\n",
    "params={\"drilldowns\":\"Nation\",\n",
    "        \"measures\":\"Population\",\n",
    "        \"year\":\"latest\"}\n",
    "\n",
    "resp = requests.get(url, params)\n",
    "\n",
    "resp.json()['data'][0]['Population']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "notes"
    }
   },
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mRunning cells with 'Python 3.10.8 64-bit' requires ipykernel package.\n",
      "\u001b[1;31mRun the following command to install 'ipykernel' into the Python environment. \n",
      "\u001b[1;31mCommand: '/usr/local/bin/python3 -m pip install ipykernel -U --user --force-reinstall'"
     ]
    }
   ],
   "source": [
    "# trick for reveal js speaker notes\n",
    "print(\"\"\"import requests\n",
    "import pprint\n",
    "\n",
    "url = \"https://datausa.io/api/data\"\n",
    "params = {\"drilldowns\":\"Nation\",\n",
    "          \"measures\": \"Population\",\n",
    "          \"year\": \"latest\"}\n",
    "\n",
    "resp = requests.get(url,params)\n",
    "resp.json()\n",
    "\"\"\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "## Do we really need of scraping at all?\n",
    "\n",
    "* Websites saldomly provides APIs.\n",
    "* Usually an API requires a **paid subscription** or some form of **restricted access** (eg. [IMDB data](https://developer.imdb.com/)).\n",
    "* Usually APIs have some kind of **requests limits** to preserve server resources.\n",
    "* API doesn't always provide the wanted data."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "To get a solid understanding we need to get a glimpse of the fundamental blocks on which scraping libraries are build upon, that is the *Fab Four* of the web tech stack.\n",
    "\n",
    "<img src=\"https://developer.mozilla.org/en-US/docs/Web/HTTP/Overview/http-layers.png\" width=40% align=center/>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## HTTP\n",
    "\n",
    "A standardized protocol based on **client-server** model, which specify the structure of the messages sent between clients and servers \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "##### In the stone age:\n",
    "\n",
    "1. Client (aka *user-agent*) **send a request** to fetch the HTML page or a resource $\\rightarrow$ *whom to contact*? \n",
    "2. Server (should) send back a **response** with the given resource $\\rightarrow$ *what could go [wrong](https://en.wikipedia.org/wiki/List_of_HTTP_status_codes#5xx_server_errors)*?\n",
    "3. Client **parse** the response, if it's a [successful one](https://en.wikipedia.org/wiki/List_of_HTTP_status_codes#2xx_success), **render** the content."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "#### Nowadays:\n",
    "\n",
    "<center> <img src=\"https://developer.mozilla.org/en-US/docs/Web/HTTP/Overview/fetching_a_page.png\" width=65% /> </center>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "We'll use [Requests](https://docs.python-requests.org/en/master/user/quickstart/) library in order to send and receive HTTP messages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mRunning cells with 'Python 3.10.8 64-bit' requires ipykernel package.\n",
      "\u001b[1;31mRun the following command to install 'ipykernel' into the Python environment. \n",
      "\u001b[1;31mCommand: '/usr/local/bin/python3 -m pip install ipykernel -U --user --force-reinstall'"
     ]
    }
   ],
   "source": [
    "# make an HTTP GET request\n",
    "url=\"https://developer.mozilla.org/en-US/\"\n",
    "resp = requests.get(url)\n",
    "\n",
    "resp.text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "notes"
    }
   },
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mRunning cells with 'Python 3.10.8 64-bit' requires ipykernel package.\n",
      "\u001b[1;31mRun the following command to install 'ipykernel' into the Python environment. \n",
      "\u001b[1;31mCommand: '/usr/local/bin/python3 -m pip install ipykernel -U --user --force-reinstall'"
     ]
    }
   ],
   "source": [
    "print(\"\"\"\n",
    "import requests\n",
    "\n",
    "url = \"https://developer.mozilla.org/\"\n",
    "url_params = {\"test_param\":23}\n",
    "resp = requests.get(url, params=url_params)\n",
    "\n",
    "resp.status_code\"\"\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "## HTML\n",
    "\n",
    "HTML main purpose is to define the **structure** of a web page.\n",
    "\n",
    "HTML files contain a series of **nested elements** that wrap the content and make it appear or beahave in a certain way."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "<center><img src=\"https://developer.mozilla.org/en-US/docs/Learn/Getting_started_with_the_web/HTML_basics/grumpy-cat-small.png\" width=70% /></center>\n",
    "\n",
    "HTML elements could also have attached *attributes*\n",
    "\n",
    "\n",
    "\n",
    "<center><img src=\"https://developer.mozilla.org/en-US/docs/Learn/Getting_started_with_the_web/HTML_basics/grumpy-cat-attribute-small.png\" width=75% /></center>\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "#### HTML DOM\n",
    "\n",
    "\n",
    "\n",
    "```HTML\n",
    "<body>\n",
    "    <h1> Title </h1>\n",
    "    <p> Lorem ipsum dolor sit amet </p>\n",
    "    <ul>\n",
    "        <li> ... </li>\n",
    "        <li> ... </li>\n",
    "        <li> ... </li>\n",
    "    </ul>\n",
    "</body>\n",
    "```\n",
    "\n",
    "\n",
    "<img src=\"https://www.dottedsquirrel.com/content/images/2021/03/csssiblings.png\" width=70% />\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "We can parse and access HTML elements using [BeautifulSoup](https://www.crummy.com/software/BeautifulSoup/bs4/doc/) library"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mRunning cells with 'Python 3.10.8 64-bit' requires ipykernel package.\n",
      "\u001b[1;31mRun the following command to install 'ipykernel' into the Python environment. \n",
      "\u001b[1;31mCommand: '/usr/local/bin/python3 -m pip install ipykernel -U --user --force-reinstall'"
     ]
    }
   ],
   "source": [
    "# parse the HTML\n",
    "\n",
    "from bs4 import BeautifulSoup\n",
    "\n",
    "html_doc = resp.text\n",
    "soup = BeautifulSoup(html_doc, \"html.parser\")\n",
    "\n",
    "type(soup.head) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "notes"
    }
   },
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mRunning cells with 'Python 3.10.8 64-bit' requires ipykernel package.\n",
      "\u001b[1;31mRun the following command to install 'ipykernel' into the Python environment. \n",
      "\u001b[1;31mCommand: '/usr/local/bin/python3 -m pip install ipykernel -U --user --force-reinstall'"
     ]
    }
   ],
   "source": [
    "print(\"\"\"\n",
    "from bs4 import BeautifulSoup\n",
    "\n",
    "html_doc = resp.content\n",
    "soup = BeautifulSoup(html_doc, 'html.parser')\n",
    "\n",
    "print(soup.prettify()[:200])\n",
    "\n",
    "print(soup.head.prettify())\n",
    "print(type(soup.head))\"\"\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "Extracting blog post titles"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mRunning cells with 'Python 3.10.8 64-bit' requires ipykernel package.\n",
      "\u001b[1;31mRun the following command to install 'ipykernel' into the Python environment. \n",
      "\u001b[1;31mCommand: '/usr/local/bin/python3 -m pip install ipykernel -U --user --force-reinstall'"
     ]
    }
   ],
   "source": [
    "# extract blog articles titles\n",
    "\n",
    "for el in soup.find_all(\"h3\"):\n",
    "    print(el.a.text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "notes"
    }
   },
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mRunning cells with 'Python 3.10.8 64-bit' requires ipykernel package.\n",
      "\u001b[1;31mRun the following command to install 'ipykernel' into the Python environment. \n",
      "\u001b[1;31mCommand: '/usr/local/bin/python3 -m pip install ipykernel -U --user --force-reinstall'"
     ]
    }
   ],
   "source": [
    "print(\"\"\"\n",
    "for el in soup.find_all(\"h3\"):\n",
    "    print(el.a.text)\n",
    "\"\"\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# CSS\n",
    "\n",
    "The main purpose of CSS is to define the HTML elements **style** (eg. sizes, colors, animations, etc...). \n",
    "\n",
    "Beforehand to specify which element to style, we need to **select** it. These is what **CSS selectors** are used for. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "CSS selectors is a *mini-language* that allows you to select one or multiple elements in a very clever way.\n",
    "```\n",
    ".classes\n",
    "#ids\n",
    "[attributes=value]\n",
    "parent child\n",
    "parent > child\n",
    "sibling ~ sibling\n",
    "sibling + sibling\n",
    ":not(element.class, element2.class)\n",
    ":is(element.class, element2.class)\n",
    "parent:has(> child)\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mRunning cells with 'Python 3.10.8 64-bit' requires ipykernel package.\n",
      "\u001b[1;31mRun the following command to install 'ipykernel' into the Python environment. \n",
      "\u001b[1;31mCommand: '/usr/local/bin/python3 -m pip install ipykernel -U --user --force-reinstall'"
     ]
    }
   ],
   "source": [
    "# build a mini dataset from Mozilla's blog articles\n",
    "\n",
    "titles = []\n",
    "authors = []\n",
    "dates = []\n",
    "articles = []\n",
    "\n",
    "  \n",
    "\n",
    "for article_el in post_elements:\n",
    "    title = article_el.select_one(\"h3 a\").text\n",
    "    titles.append(title)\n",
    "    \n",
    "    post_meta = article_el.select_one(\"p.post-meta\")\n",
    "    data, author = post_meta.text.replace(\"Posted \", \"\").strip().split(\" by \")\n",
    "    \n",
    "    dates.append(data)\n",
    "    authors.append(author)\n",
    "    \n",
    "    articles.append(article_el.select_one(\"p:not(.post-meta)\").text)\n",
    "  \n",
    "import pandas as pd\n",
    "\n",
    "pd.DataFrame({\"title\":titles, \"authors\":authors}).to_csv(\"mini_dataset.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "notes"
    }
   },
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mRunning cells with 'Python 3.10.8 64-bit' requires ipykernel package.\n",
      "\u001b[1;31mRun the following command to install 'ipykernel' into the Python environment. \n",
      "\u001b[1;31mCommand: '/usr/local/bin/python3 -m pip install ipykernel -U --user --force-reinstall'"
     ]
    }
   ],
   "source": [
    "print(\"\"\"\n",
    "post_elements = soup.select(\"div.blog-feed > ul > li\")\n",
    "\n",
    "titles = []\n",
    "urls = []\n",
    "descriptions = []\n",
    "dates = []\n",
    "authors = []\n",
    "\n",
    "for post_el in post_elements:\n",
    "    titles.append(post_el.h3.text) \n",
    "    \n",
    "    urls.append(post_el.h3.a[\"href\"])\n",
    "    \n",
    "    post_meta = post_el.select_one(\"p.post-meta\").text\n",
    "    date, author = post_meta.replace(\"Posted\",\"\").strip().split(\" by \") \n",
    "    dates.append(date)\n",
    "    authors.append(author)\n",
    "    \n",
    "    descriptions.append(post_el.select_one(\"p:not(.post-meta)\").text) \n",
    "\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "mini_dataset = pd.DataFrame({\"title\": titles, \"url\":urls,\n",
    "                             \"description\": descriptions, \"dates\": dates,\n",
    "                             \"author\": authors})\n",
    "\n",
    "mini_dataset.to_csv(\"mini_dataset_mozilla.csv\")\"\"\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "#### Some stuff to notice:\n",
    "* the selected element is always the **right-most**.\n",
    "* the selection is always **relative** to the (root) node we are working on."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## All you need is XPath\n",
    "\n",
    "Query language for selecting HTML (XML) elements.\n",
    "\n",
    "<img src=\"https://www.softwaretestinghelp.com/wp-content/qa/uploads/2019/05/XPATH-Syntax-screenshot-1-1.png\" width=60% />\n",
    "\n",
    "Some advantages:\n",
    "* Bidirectional flow $\\rightarrow$ moving left-right, up-down\n",
    "* Partial matching with *contains()*\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# JavaScript\n",
    "\n",
    "JS main purpose is to add **dynamic functionalities and behaviours** to a web page.\n",
    "\n",
    "JS code **could change** the underlying HTML structure or elements styles, but can also \"silently\" send HTTP requests to other servers (eg. for retrieving data from web api)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "#### Headless browsers to the rescue\n",
    "\n",
    "Provides automated control of a web page without actually render and display it:\n",
    "* js running\n",
    "* automatic interaction (eg. click on an button, compiling a form, etc.)\n",
    "\n",
    "Some solutions:\n",
    "* [requests-html](https://github.com/psf/requests-html)\n",
    "* [Selenium](https://selenium.dev)\n",
    "* [Scrapy-selenium](https://github.com/clemfromspace/scrapy-selenium)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    " #### Scrapy\n",
    "    \n",
    "Scrapy is a *framework*, so it expects from you to:\n",
    "\n",
    "* fit your mental model to the framework conceptual model and execution flow\n",
    "* follow conventions and rules (eg. directories stucture)\n",
    "* extend and use framework' classes and tools"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "#### How Scrapy works?\n",
    "\n",
    "<img src=\"https://docs.scrapy.org/en/latest/_images/scrapy_architecture_02.png\" width=60% />"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "Crawling [Pagella Politica](https://pagellapolitica.it/) to build a fact checking dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "#### Scrapy CLI\n",
    "\n",
    "Scray provides a CLI tool to manage projects and spiders"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "To initialize a project:\n",
    "\n",
    "```scrapy startproject fact_checking```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "To create a spider:\n",
    "\n",
    "`scrapy genspider pagellapolitica pagellapolitica.it`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "To run the spider:\n",
    "\n",
    "`scrapy crawl pagellapolitica`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "References\n",
    "\n",
    "* for HTTP, HTML, CSS, JS: [MDN web docs](https://developer.mozilla.org/en-US/docs/Web)\n",
    "* for CSS selectors: [dotted squirrel visual guide](https://www.dottedsquirrel.com/the-ultimate-visual-guide-to-css-selectors/)\n",
    "* Scrapy: [official documentation](https://docs.scrapy.org/en/latest/)\n",
    "\n",
    "Further readings: Seppe Vanden, BrouckeBart Baesens; [Practical Web Scraping for Data Science](https://link.springer.com/book/10.1007/978-1-4842-3582-9)\n"
   ]
  }
 ],
 "metadata": {
  "celltoolbar": "Slideshow",
  "kernelspec": {
   "display_name": "Python 3.10.8 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  },
  "rise": {
   "scroll": true
  },
  "vscode": {
   "interpreter": {
    "hash": "aee8b7b246df8f9039afb4144a1f6fd8d2ca17a180786b69acc140d282b71a49"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
